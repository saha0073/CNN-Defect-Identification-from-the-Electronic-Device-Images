{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import pickle\n",
    "import skimage\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, LambdaCallback, CSVLogger\n",
    "\n",
    "from general_utils import encode_mask_to_rgb, get_normalized_image\n",
    "from data_loader import DataLoader\n",
    "from model_pipeline import ModelPipeline\n",
    "from predictions_pipeline import PredictionsPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_df = pd.read_pickle('data//embeddings_df.pkl')\n",
    "data_dir = 'data//dataset_for_m1_model_combined//'\n",
    "rgb_df_fp = 'data//rgb_calculations.pkl'\n",
    "rgb_df = pd.read_pickle(rgb_df_fp)\n",
    "model_name = 'saved_models//supervised_unet.h5'\n",
    "#vgg_weights_path = \"VGG16NOTOP.h5\"\n",
    "im_height = 256\n",
    "im_width = 768\n",
    "\n",
    "data_loader = DataLoader(path=data_dir, im_height=im_height, im_width=im_width)\n",
    "model_pipeline = ModelPipeline(batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y, X_ids = data_loader.get_only_labeled_data(path=data_dir, masks_folder=\"masks_all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, valid_dataset, params = model_pipeline.get_images_and_masks_datasets(X, Y, channel_normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unet(kernel = 3, pool_size = (2, 2), input_height=256, input_width=768, channel=3, n_classes=5):\n",
    "\n",
    "    img_input = Input(shape=(input_height, input_width, channel))\n",
    "\n",
    "    ###################### Encoder 1 ############################\n",
    "    c1 = Convolution2D(64, (kernel, kernel), padding=\"same\", activation='selu')(img_input)\n",
    "    c2 = Convolution2D(64, (kernel, kernel), padding=\"same\", activation='selu')(c1)\n",
    "    p1 = MaxPooling2D(pool_size)(c1)\n",
    "\n",
    "    ###################### Encoder 2 ############################\n",
    "    c2 = Convolution2D(128, (kernel, kernel), padding=\"same\", activation='selu')(p1)\n",
    "    c2 = Convolution2D(128, (kernel, kernel), padding=\"same\", activation='selu')(c2)\n",
    "    p2 = MaxPooling2D(pool_size)(c2)\n",
    "\n",
    "    ###################### Encoder 3 ############################\n",
    "    c3 = Convolution2D(256, (kernel, kernel), padding=\"same\", activation='selu')(p2)\n",
    "    c3 = Convolution2D(256, (kernel, kernel), padding=\"same\", activation='selu')(c3)\n",
    "    p3 = MaxPooling2D(pool_size)(c3)\n",
    "    p3 = Dropout(0.2)(p3)\n",
    "\n",
    "    ###################### Encoder 4 ############################\n",
    "    c4 = Convolution2D(512, (kernel, kernel), padding=\"same\", activation='selu')(p3)\n",
    "    c4 = Convolution2D(512, (kernel, kernel), padding=\"same\", activation='selu')(c4)\n",
    "    p4 = MaxPooling2D(pool_size)(c4)\n",
    "    p4 = Dropout(0.2)(p4)\n",
    "\n",
    "    ###################### BOTTLENECK ###########################\n",
    "    d1 = Convolution2D(512, (kernel, kernel), padding=\"same\", activation='selu')(p4)\n",
    "    d1 = Convolution2D(512, (kernel, kernel), padding=\"same\", activation='selu')(d1)\n",
    "    d1 = Dropout(0.5)(d1)\n",
    "\n",
    "    ###################### Decoder 1 ############################\n",
    "    u1 = concatenate([UpSampling2D(2)(d1), c4])\n",
    "    c5 = Convolution2D(512, (kernel, kernel), padding=\"same\")(u1)\n",
    "    c5 = BatchNormalization()(c5)\n",
    "    c5 = Activation('selu')(c5)\n",
    "    c5 = Convolution2D(256, (kernel, kernel), padding=\"same\")(c5)\n",
    "    c5 = BatchNormalization()(c5)\n",
    "    c5 = Activation('selu')(c5)\n",
    "    c5 = Dropout(0.2)(c5)\n",
    "\n",
    "    ###################### Decoder 2 ############################\n",
    "    u2 = concatenate([UpSampling2D(2)(c5), c3])\n",
    "    c6 = Convolution2D(256, (kernel, kernel), padding=\"same\")(u2)\n",
    "    c6 = BatchNormalization()(c6)\n",
    "    c6 = Activation('selu')(c6)\n",
    "    c6 = Convolution2D(128, (kernel, kernel), padding=\"same\")(c6)\n",
    "    c6 = BatchNormalization()(c6)\n",
    "    c6 = Activation('selu')(c6)\n",
    "    c6 = Dropout(0.2)(c6)\n",
    "\n",
    "    ###################### Decoder 3 ############################\n",
    "    u3 = concatenate([UpSampling2D(2)(c6), c2])\n",
    "    c7 = Convolution2D(128, (kernel, kernel), padding=\"same\")(u3)\n",
    "    c7 = BatchNormalization()(c7)\n",
    "    c7 = Activation('selu')(c7)\n",
    "    c7 = Convolution2D(64, (kernel, kernel), padding=\"same\")(c7)\n",
    "    c7 = BatchNormalization()(c7)\n",
    "    c7 = Activation('selu')(c7)\n",
    "\n",
    "    ###################### Decoder 4 ############################\n",
    "    u4 = concatenate([UpSampling2D(2)(c7), c1])\n",
    "    c8 = Convolution2D(64, (kernel, kernel), padding=\"same\")(u4)\n",
    "    c8 = BatchNormalization()(c8)\n",
    "    c8 = Activation('selu')(c8)\n",
    "    c8 = Convolution2D(64, (kernel, kernel), padding=\"same\")(c8)\n",
    "    c8 = BatchNormalization()(c8)\n",
    "    c8 = Activation('selu')(c8)\n",
    "\n",
    "    c8 = Convolution2D(n_classes, (kernel, kernel), padding=\"same\")(c8)\n",
    "\n",
    "    # Output layer must be manually cast to float32 when using mixed precision\n",
    "    softmax_outputs = tf.keras.layers.Activation(\"softmax\", name='softmax_predictions', dtype=\"float32\")(c8)\n",
    "\n",
    "    model = tf.keras.Model(img_input, softmax_outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_unet(input_height=im_height, input_width=im_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_num = 120 #  # try different numbers to find a good example to plot during training\n",
    "image = X[img_num]\n",
    "#sample_image = get_normalized_image(image, rgb_df)\n",
    "sample_image = image.astype(np.float32) / 255\n",
    "sample_mask = np.argmax(Y[img_num], axis=-1)\n",
    "sample_mask = encode_mask_to_rgb(sample_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(display_list):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    title = [\"Image Input\", \"Predicted Mask\", \"True Mask\"]\n",
    "    for i in range(len(display_list)):\n",
    "        plt.subplot(1, len(display_list), i+1)\n",
    "        plt.title(title[i])\n",
    "        plt.imshow(display_list[i])\n",
    "        plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def show_predictions(epoch, logs=None):\n",
    "\n",
    "    prediction = model.predict(sample_image[tf.newaxis, ...])\n",
    "    prediction = np.reshape(prediction, (prediction.shape[1], prediction.shape[2], prediction.shape[3]))\n",
    "    prediction = np.argmax(prediction, axis=-1)\n",
    "    prediction = encode_mask_to_rgb(prediction)\n",
    "    display([image.astype(np.uint8), prediction, sample_mask])\n",
    "\n",
    "show_predictions(epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try: longer patience for ReduceLROnPlateau\n",
    "callbacks = [\n",
    "    LambdaCallback(on_epoch_end=show_predictions),\n",
    "    EarlyStopping(monitor='val_dice_coef', mode = 'max', patience=15, verbose=2), \n",
    "    ReduceLROnPlateau(monitor='val_dice_coef', factor=0.1, patience=5, min_lr=1e-10, mode = 'max', verbose=2),\n",
    "    ModelCheckpoint(model_name, monitor='val_dice_coef', verbose=2, mode='max', save_best_only=True, save_weights_only=True)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = model_pipeline.compile_and_train_supervised(model, train_dataset, valid_dataset, params, callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_pipeline = PredictionsPipeline(path=data_dir, model=model, rgb_df_fp=rgb_df_fp, im_height=im_height, im_width=im_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_uncertainty, y_defect_type = pred_pipeline.export_predictions_and_heatmaps(normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_df[\"uncertainty_label\"] = y_uncertainty\n",
    "embeddings_df[\"defect_label\"] = y_defect_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings_df.to_pickle(\"data//embeddings_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tsne_graph(df, defect_color_scale=False, discrete_colors=True):\n",
    "    \"\"\"Creates tsne graph as a plotly.go figure\n",
    "    arguments\n",
    "        df: pandas dataframe with columns for image ids, labels, as well as x and y coordinates of the t-sne embeddings for each datapoint.\n",
    "        defect_color_scale: when True, colors are from a pre-defined color map \n",
    "        discrete_colors: uses a plotly discrete colorscale to show colors for any number of classes\n",
    "    \"\"\"\n",
    "    \n",
    "    df.to_pickle(\"data//temp_df.pkl\")\n",
    "    \n",
    "    if defect_color_scale:\n",
    "        color_scale = ['rgb(0,0,0)', 'rgb(0,0,255)', 'rgb(255,0,0)', 'rgb(0,255,255)', 'rgb(255,255,0)']\n",
    "        label_df = df['defect_label']\n",
    "    elif discrete_colors:\n",
    "        color_scale = px.colors.qualitative.Alphabet\n",
    "        label_df = df['cluster_label']\n",
    "    else:\n",
    "        color_scale = \"thermal\"\n",
    "        label_df = df['uncertainty_label']\n",
    "        \n",
    "    fig = go.Figure(\n",
    "        data=go.Scatter(\n",
    "            x=df['x'],\n",
    "            y=df['y'],\n",
    "            mode='markers',\n",
    "            marker_size = 8,\n",
    "            marker_color=label_df,\n",
    "            marker_colorscale = color_scale,\n",
    "            marker_opacity = 0.7,\n",
    "            text=df['Img_ID'],\n",
    "            customdata = label_df,\n",
    "            hoverinfo = 'text',\n",
    "            showlegend=False,\n",
    "        )\n",
    "    ) \n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=dict(\n",
    "                text=\"t-SNE Embeddings\", \n",
    "                x=0.5, \n",
    "                font=dict(size=32, family=\"Calibri Light, HelveticaNeue\")\n",
    "        ),\n",
    "        legend=dict(orientation='v', x=1, y=0, bordercolor='Grey', borderwidth=1),\n",
    "        #height=500,\n",
    "        xaxis = dict(visible=False),\n",
    "        yaxis = dict(visible=False),\n",
    "        paper_bgcolor='rgb(255,255,255)', \n",
    "        plot_bgcolor='rgb(255,255,255)'\n",
    "    )\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = create_tsne_graph(embeddings_df, defect_color_scale=False, discrete_colors=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = create_tsne_graph(embeddings_df, defect_color_scale=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow2_latest_p37)",
   "language": "python",
   "name": "conda_tensorflow2_latest_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
